Root Cause Analysis - ExpressRoute \ ExpressRoute Circuits Amsterdam
Summary of impact: Between 21:03 UTC on 01 Jun 2017 and 22:04 UTC on the 02 Jun 2017, ExpressRoute customers connecting to Azure services through ExpressRoute public peering in Amsterdam may have experienced a loss in network connectivity. Customers with redundant connectivity conﬁgurations may have experienced a partial loss in connectivity. This was caused by an ExpressRoute router conﬁguration size which overloaded router resources. Once the issue was detected, conﬁguration was partitioned across multiple devices to mitigate the issue. During this time customers could have failed over to using a 2nd ExpressRoute circuit in the geo or could have failed back to the internet. Root cause and mitigation: A subset of ExpressRoute edge routers in Amsterdam were overloaded due to the size of conﬁguration. The source NAT on the public peering was overloaded and resulted in loss of connectivity. ExpressRoute routers are redundant in an active/active conﬁguration. A device failover restored connectivity for some time during this period. Upon failover, the second device also got affected by overload and experienced impact. Next steps: We are continuously taking steps to improve the Microsoft Azure Platform and our processes to help ensure such incidents do not occur in the future, and in this case it includes (but is not limited to): 1. [Ongoing] Prevent conﬁguration overload on devices. 2. [Ongoing] Reinforce existing recommend that all customers deploy ExpressRoute with an active-active conﬁguration. 3. [Ongoing] Enhance router resource monitoring to alert before resource limits are reached. 4. [Coming] Support ExpressRoute public peering preﬁxes on MSFT peering that does not use device NAT. 5. [Coming] Add ability to re-balance load automatically. Direct new connections to new routers in the same location. Provide feedback: Please help us improve the Azure customer communications experience by taking our survey https://survey.microsoft.com/380673