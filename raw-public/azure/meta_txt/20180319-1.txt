RCA - SQL Database - West Europe
Summary of impact: Between 11:00 UTC on 19 Mar 2018 and 10:30 UTC on 20 Mar 2018, a subset of customers using SQL Database in West Europe may have experienced difficulties connecting to databases hosted in this region. Service management operations such as scaling Database performance tier were also impacted. During the impact period, some customers using API Management in the region may have also experienced service degradation. Root cause and mitigation: As part of continuous improvements to support high performance levels, a code deployment was rolled out starting at 02:45 UTC 19 Mar 2018, each backend node downloads the new image from storage. During the regular scheduled code deployment, a set of heavily loaded nodes in the region experienced contention with the image download process. While deployment proceeded as expected across other regions, in West Europe we experienced tensile point which dramatically increased the rate and caused nodes to become unhealthy. The specific point was due to a combination of factors & heavy load on the region, a bug causing an increase in the size of the image being downloaded, and a pre-existing configuration mismatch on a small set of scale units in the region. In addition, our monitoring system had an unrelated issue during part of the incident time window, delaying our detection and impacting our ability to quickly diagnose the issues. Our health monitoring eventually caught up and a rollback was triggered, however the detection threshold allowed too much impact prior to rollback, and the rollback itself took much longer than expected, due to the same tensile point. Once the rollback of the deployment completed, SQL engineers confirmed full mitigation and normal operations were restored by 10:30 UTC 20 Mar 2018. Next steps: We sincerely apologize for the impact to affected customers. We are continuously taking steps to improve the Microsoft Azure Platform and our processes to help ensure such incidents do not occur in the future. In this case, this includes (but is not limited to): 1. Roll out fix to resolve the bug impacting image download contentions and configuration mismatch in a subset of scale units with urgent priority. [In progress] 2. Enhance dial tone alerting to provide more reliable telemetry for monitoring system failover. [In progress] 3. Improve the configuration for health thresholds at the node level to trigger auto rollbacks. [In progress] 4. Refine drift monitoring to detect specific configuration mismatch to prevent future occurrence. [In progress] 5. Add further tensile tests to our validation pipeline to detect such issues prior rolling to production. [in progress] Provide feedback: Please help us improve the Azure customer communications experience by taking our survey https://survey.microsoft.com/664182
